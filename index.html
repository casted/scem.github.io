<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Diffusion-Based Low-Light Image Enhancement with Color and Luminance Priors (ICRA 2026).">
  <meta name="keywords" content="low-light image enhancement, diffusion models, conditional diffusion, SCEM">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Diffusion-Based Low-Light Image Enhancement with Color and Luminance Priors</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
    .paper-title {
      font-size: 56px;
      font-weight: 800;
      line-height: 1.08;
      letter-spacing: -0.02em;
      margin-bottom: 0.35rem;
    }
    .cool-word {
      display: inline-block;
      padding: 0 2px;
      -webkit-text-stroke: 3px rgba(0,0,0,0.08);
      text-shadow:
        3px 3px 0 rgba(255, 0, 0, 0.65),
       -3px 0 0 rgba(0, 180, 255, 0.75),
        0 -3px 0 rgba(70, 220, 120, 0.65);
    }
    .c-gray { color: #8e8e8e; }
    .c-yellow { color: #f4d03f; }
    .c-orange { color: #e67e22; }
    .c-purple { color: #8e44ad; }
    .c-green { color: #2ecc71; }
    @media (max-width: 768px) {
      .paper-title { font-size: 36px; }
    }
  </style>

</head>
<body id="top">

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a class="navbar-item" href="#top">
      <strong>DiffusionLLIE</strong>
    </a>
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false" data-target="navbarBasicExample">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title paper-title"><span class="cool-word">Diffusion<span class="c-yellow">-</span>Based</span> <span class="c-gray">Low-Light</span> Image Enhancement<br>with <span class="c-orange">Color</span> and <span class="c-green">Luminance</span> Priors</h1>
          <div class="is-size-5 publication-authors">
  <span class="author-block">Xuanshuo Fu</sup>,</span>
  <span class="author-block">Lei Kang</sup><span style="font-size: 0.9em;">†</span>,</span>
  <span class="author-block">Javier Vazquez-Corral</sup></span>
</div>
<div class="is-size-5 publication-authors">
  <span class="author-block"><sup>1</sup>Computer Vision Center (CVC), Universitat Autònoma de Barcelona, Spain</span>
</div>
<div class="is-size-6 publication-authors">
  <span class="author-block">† corresponding author</span>
</div>
          <div class="column has-text-centered">
            <div class="publication-links">
  <!-- PDF Link -->
  <span class="link-block">
    <a href="./static/pdfs/ICRA2026_DiffusionLLIE.pdf"
       class="external-link button is-normal is-rounded is-dark">
      <span class="icon">
          <i class="fas fa-file-pdf"></i>
      </span>
      <span>Paper (PDF)</span>
    </a>
  </span>

  <!-- Code Link -->
  <span class="link-block">
    <a href="#"
       class="external-link button is-normal is-rounded is-dark">
      <span class="icon">
          <i class="fab fa-github"></i>
      </span>
      <span>Code (coming)</span>
    </a>
  </span>

  <!-- Supplementary (optional) -->
  <span class="link-block">
    <a href="#bibtex"
       class="external-link button is-normal is-rounded is-dark">
      <span class="icon">
          <i class="fas fa-quote-right"></i>
      </span>
      <span>BibTeX</span>
    </a>
  </span>
</div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Low-light images often suffer from low contrast, noise, and color distortion, degrading visual quality and impairing downstream vision tasks. We propose a conditional diffusion framework for low-light image enhancement that incorporates a Structured Control Embedding Module (SCEM). SCEM decomposes a low-light image into four informative components—illumination, illumination-invariant features, shadow priors, and color-invariant cues—which serve as control signals to condition a U-Net–based diffusion model trained with a simplified noise-prediction loss. The resulting SCEM-equipped diffusion method enforces structured enhancement guided by physical priors. Our model is trained only on LOLv1 and evaluated without fine-tuning on LOLv2-real, LSRW, DICM, MEF, and LIME, achieving state-of-the-art quantitative and perceptual metrics and strong cross-dataset generalization. Code will be released upon acceptance.
          </p>
        </div>

<h3 class="title is-4">Fig. 1: Quantitative comparisons</h3>
<div class="columns is-vcentered">
  <div class="column">
    <figure class="image">
      <img src="./static/images/Table1Radarchart_gai.png" alt="Fig.1(a) radar chart on LOLv1/LOLv2-real/LSRW (with GT)" style="display:block; max-width:100%; height:auto;">
    </figure>
    <p class="has-text-centered is-size-7">(a) PSNR/SSIM/LPIPS/FID on LOLv1, LOLv2-real, and LSRW (with ground truth).</p>
  </div>
  <div class="column">
    <figure class="image">
      <img src="./static/images/Table3Radarchart_gai.png" alt="Fig.1(b) radar chart on DICM/MEF/LIME (no GT)" style="display:block; max-width:100%; height:auto;">
    </figure>
    <p class="has-text-centered is-size-7">(b) NIQE/BRISQUE/PI on DICM, MEF, and LIME (no ground truth).</p>
  </div>
</div>
<div class="content has-text-justified" style="margin-top: 0.75rem;">
  <p>
    Fig. 1 reports both <strong>fidelity</strong> metrics (PSNR/SSIM) and <strong>perceptual</strong> metrics (LPIPS/FID, NIQE/BRISQUE/PI)
    across datasets with and without ground truth. Our SCEM-equipped diffusion model remains consistently strong across all axes,
    highlighting robust generalization beyond the training distribution.
  </p>
</div>
      </div>
    </div>
    <!--/ Abstract. -->


  </div>
</section>

<section class="section" id="method">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
          <p>
            We condition a U-Net diffusion backbone with structured priors extracted by the <strong>Structured Control Embedding Module (SCEM)</strong>.
            Given a low-light input, SCEM produces four complementary control signals: (1) illumination, (2) illumination-invariant features,
            (3) shadow priors, and (4) color-invariant cues. These priors provide physically meaningful guidance during denoising, enabling
            robust enhancement under complex lighting and color shifts.
          </p>

<h3 class="title is-4" style="margin-top: 1.25rem;">Fig. 2: Structured Control Embedding Module (SCEM)</h3>
<figure class="image" style="margin-top: 0.5rem;">
  <img src="./static/images/net.png" alt="Fig.2 SCEM module and diffusion pipeline" style="display:block; max-width:100%; height:auto;">
</figure>
<p class="has-text-centered is-size-7" style="margin-top: 0.5rem;">
  SCEM decomposes a low-light image into illumination, illumination-invariant features, shadow priors, and color-invariant cues to condition the diffusion model.
</p>
          <p>
            Fig. 2 illustrates the overall pipeline: the SCEM controls are concatenated and injected into the diffusion model to steer the
            enhancement process with a simplified noise-prediction objective.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="results">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Results</h2>
        <div class="content has-text-justified">
          <p>
            We train only on <strong>LOLv1</strong> and evaluate <em>without fine-tuning</em> on LOLv2-real, LSRW, DICM, MEF, and LIME.
            Fig. 1 summarizes quantitative comparisons across datasets with and without ground truth, and Fig. 3 shows qualitative results.
            The proposed method achieves state-of-the-art performance on both fidelity (PSNR/SSIM) and perceptual metrics (LPIPS/FID, NIQE/BRISQUE/PI),
            demonstrating strong cross-dataset generalization.
          </p>
        </div>
        <h3 class="title is-4" style="margin-top: 1.25rem;">Fig. 3: Qualitative comparison</h3>
        <figure class="image" style="margin-top: 0.5rem;">
          <img src="./static/images/comper.png" alt="Fig.3 qualitative comparisons">
        </figure>

      </div>
    </div>
  </div>
</section>

<section class="section" id="bibtex">
  <div class="container is-max-desktop content">
    <h2 class="title is-3">BibTeX</h2>
    <pre><code>@inproceedings{fu2026diffusionllie,
  title     = {Diffusion-Based Low-Light Image Enhancement with Color and Luminance Priors},
  author    = {Fu, Xuanshuo and Kang, Lei and Vazquez-Corral, Javier},
  booktitle = {Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)},
  year      = {2026}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/pdfs/ICRA2026_DiffusionLLIE.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="#" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
